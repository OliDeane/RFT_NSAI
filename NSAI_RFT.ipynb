{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuro-Symbolic AI\n",
    "\n",
    "## RFT Dataset\n",
    "\n",
    "### Contents\n",
    "\n",
    "- Generate Dataset\n",
    "- Perception Model\n",
    "- Semantic Parser\n",
    "- Program Executor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from img_utils import *\n",
    "from data_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comaprison to NS-VQA sample\n",
    "\n",
    "(img, objects, relations, norelations) = build_sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([ 55, 179]), 'r', (40, 164, 70, 194)),\n",
       " (1, array([130,  31]), 'c', (115, 16, 145, 46)),\n",
       " (2, array([115, 154]), 'r', (100, 139, 130, 169)),\n",
       " (3, array([ 69, 103]), 'c', (54, 88, 84, 118)),\n",
       " (4, array([77, 48]), 'r', (62, 33, 92, 63)),\n",
       " (5, array([115, 192]), 'r', (100, 177, 130, 207))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "\n",
    "# Dataset params\n",
    "img_size = 224\n",
    "size = 15 # the object size?\n",
    "question_size = 10 # 6 for one-hot vector of color, 1 for question type, 3 for question subtype\n",
    "q_type_idx = 6 # type of question\n",
    "sub_q_type_idx = 7 # \n",
    "nb_questions = 10 # questions per image. \n",
    "\n",
    "# Possibles Answers : [yes, no, rectangle, circle, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "colors = [\n",
    "    (0,0,255), # red\n",
    "    (0,255,0), # green\n",
    "    (255,0,0), # blue\n",
    "    (0,156,255), # orange\n",
    "    (128,128,128), # gray (128,128,128)- not working, replaced with black\n",
    "    (0,255,255) # yellow - appears same as orange\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFT Same-Different Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a sample\n",
    "\n",
    "def build_image(colors, img_size, size):\n",
    "    # choose two random colors\n",
    "# for i in range(16):\n",
    "    color1 = ()\n",
    "    color2 = ()\n",
    "    while color1 == color2:\n",
    "        color1 = colors[random.randint(0,5)]\n",
    "        color2 = colors[random.randint(0,5)]\n",
    "\n",
    "    positions = [([25,25],[65,25]),([25,175],[65,175]),([160,25],[200,25]), ([160,175],[200,175])]\n",
    "    random.shuffle(positions)\n",
    "\n",
    "    img = np.ones((img_size,img_size,3)) * 255\n",
    "\n",
    "    img = draw_sCsS(img, positions, color1, size = size)\n",
    "    img = draw_sCdS(img, positions, color2, size = size)\n",
    "    img = draw_dCsS(img, positions, color1, color2, size = size)\n",
    "    img = draw_dCdS(img, positions, color1, color2, size = size)\n",
    "\n",
    "    img = (img).astype('uint8')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_img_dataset with params colors, img_size, size\n",
    "for i in range(16):\n",
    "    img = build_image(colors, img_size, size)\n",
    "    cv2.imwrite(f'rft_dataset/{i}.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biuld Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_q_template(idx):\n",
    "    question_types = [['the same color', 'the same shape'],['the same color','a different shape'],\\\n",
    "        ['a different color','the same shape'], ['a different color','a different shape']]\n",
    "    \n",
    "    order = [0,1]\n",
    "    random.shuffle(order)\n",
    "    return f'Which pair is {question_types[idx][order[0]]} and {question_types[idx][order[1]]}?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Which pair is the same shape and a different color?',\n",
       " 'Which pair is a different shape and the same color?',\n",
       " 'Which pair is the same color and the same shape?',\n",
       " 'Which pair is a different color and a different shape?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [fill_q_template(i) for i in [0,1,2,3]]\n",
    "random.shuffle(questions)\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training dataset\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "584e64d791e059b51eb4f8b025bc77b5e4b36bec6872b60b56cee14078c0c808"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('PytorchEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
